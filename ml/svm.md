---
categories: MachineLearning

tags: 
  - SVM

title: SVM

date: 2017-03-27
---

# 前言

SVM是在高维特征空间使用线性函数假设空间的学习系统，它由一个来自最优化理论的学习算法训练，该算法实现了一个由统计学习理论导出的学习偏置。

SVM是线性分类器的一种加深，SVM有一些显而易见的几何意义，但由于它用到的一些数学工具比较深奥，所以理解起来非常困难。SVM是机器学习领域若干标准技术的集大成者。它集成了最大间隔超平面、Mercer核、凸二次规划、稀疏解和松弛变量等多项技术。SVM思想直观，但细节异常复杂，对非数学专业的人来讲自己看书很难看懂。

SVM可以很好的处理非线性边界，而且计算的复杂度仅比线性的情形多一点。

SVM源于Vapnik和Chervonekis关于统计学习的早期工作，第一篇有关论文由Boser、Guyon、Vapnik发表在1992年（理   解一个算法最好的方式是看原始论文，当然，如果能看懂）。

# SVM 几何意义

SVM 的几何意义比较容易理解，因此我们先看看SVM几何意义。

## 线性分类

首先看看线性分类，简单的说就是如果用一个线性函数可以将两类样本完全分开，就称这些样本是“线性可分”的。

对线性可分的情况，找出一根可以将数据分割开的直线并不困难，但怎么样找出分割最好的那根线。如下图所示
![image](http://blog.geekidentity.com/images/svm/svm1.jpg)

SVM 采用下面方式评估最优的分割线

* 分割线向左边样本集靠拢，直到刚好经过左边样本集中离分割线最近的点；
* 分割线向右边样本集靠拢，直到刚好经过右边样本集中的离分割线最近的点。
* 左右这两条线称为支撑平面（为什么叫平面，因为这里是二维空间，当N维空间时这两条线就是超平面），如果这两个支撑平面的距离达到了最大值，我们就认为这个分离平面是最好的。
* 刚好经过的点支持向量
* 中间的区域称为（隔离地带）,隔离地带越宽则分类效果越好。
* 最终求出的分离平面与两个支撑平面距离相等且平行。
![image](http://blog.geekidentity.com/images/svm/svm2.jpg)

所以求支持向量的算法叫支持向量机

# SVM 数学原理

假设可以写成下面形式

![image](http://blog.geekidentity.com/images/svm/wx+b=0.jpg)

其实w、x都是向量，b是标量w、x是点乘即内积：
```math
w = (w1, w2, w3)

x = (x1, x2, x3) 
```
不明白为什么可以这样表示的请看[这里](http://blog.csdn.net/handforever/article/details/14106309)

所以求超平面就是求w、b

* b 可以理解为直线的截距
* w 可以理解为直线的法向量
* 

* 使用样例来合成计算机程序的过程称为学习方法，其中当样例是由输入/输出对给出时，称为监督学习。
* 有关输入/输出函数关系的样例称为训练数。
* 当输入到输出存在内在函数时，该函数称为目标函数。
* 由学习算法输出的对目标函数的估计称为学习问题的解。
* 对于分类问题，该函数有时称为决策函数。
* 有二元输出的问题称为二类问题，有多个类别的问题称为多类问题，而实数值输出的问题称为回归问题。
* 一个假设正确分类训练集之外数据的能力称为泛化性，这是要优化的属性。
* 为了得到一致假设而使假设变得过度复杂称为过拟合。